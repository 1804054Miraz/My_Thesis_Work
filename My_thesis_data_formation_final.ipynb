{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1804054Miraz/My_Thesis_Work/blob/main/My_thesis_data_formation_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKW1ocL_yeHu"
      },
      "source": [
        "448, 450, 451, 453, 454, 455, 456, 457, 458, 459, 460, 461, 402"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U88VCeWvzm1v"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "import numpy as np\n",
        "import tarfile\n",
        "import gzip\n",
        "import os\n",
        "dfs = []\n",
        "serial=[]\n",
        "\n",
        "# Specify the path to the .tar.gz file\n",
        "tar_file_path = '/content/drive/MyDrive/Dataset/eeg_full/co2c1000367.tar.gz'\n",
        "output_directory = \"/content/drive/MyDrive/Dataset/EEG_FULL/Non-alcoholic/367/\"\n",
        "# !mkdir /content/drive/MyDrive/Dataset/EEG_FULL/Non-alcoholic/367"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adUS2okmo9wQ",
        "outputId": "8405715b-c066-406c-f6ed-57f4ee97e317"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['co2c1000367', 'co2c1000367/co2c1000367.rd.001.gz', 'co2c1000367/co2c1000367.rd.002.gz', 'co2c1000367/co2c1000367.rd.003.gz', 'co2c1000367/co2c1000367.rd.004.gz', 'co2c1000367/co2c1000367.rd.005.gz', 'co2c1000367/co2c1000367.rd.006.gz', 'co2c1000367/co2c1000367.rd.007.gz', 'co2c1000367/co2c1000367.rd.009.gz', 'co2c1000367/co2c1000367.rd.010.gz', 'co2c1000367/co2c1000367.rd.011.gz', 'co2c1000367/co2c1000367.rd.012.gz', 'co2c1000367/co2c1000367.rd.013.gz', 'co2c1000367/co2c1000367.rd.014.gz', 'co2c1000367/co2c1000367.rd.015.gz', 'co2c1000367/co2c1000367.rd.016.gz', 'co2c1000367/co2c1000367.rd.017.gz', 'co2c1000367/co2c1000367.rd.018.gz', 'co2c1000367/co2c1000367.rd.019.gz', 'co2c1000367/co2c1000367.rd.020.gz', 'co2c1000367/co2c1000367.rd.021.gz', 'co2c1000367/co2c1000367.rd.022.gz', 'co2c1000367/co2c1000367.rd.023.gz', 'co2c1000367/co2c1000367.rd.024.gz', 'co2c1000367/co2c1000367.rd.025.gz', 'co2c1000367/co2c1000367.rd.026.gz', 'co2c1000367/co2c1000367.rd.027.gz', 'co2c1000367/co2c1000367.rd.028.gz', 'co2c1000367/co2c1000367.rd.029.gz', 'co2c1000367/co2c1000367.rd.030.gz', 'co2c1000367/co2c1000367.rd.031.gz', 'co2c1000367/co2c1000367.rd.032.gz', 'co2c1000367/co2c1000367.rd.033.gz', 'co2c1000367/co2c1000367.rd.034.gz', 'co2c1000367/co2c1000367.rd.035.gz', 'co2c1000367/co2c1000367.rd.036.gz', 'co2c1000367/co2c1000367.rd.037.gz', 'co2c1000367/co2c1000367.rd.038.gz', 'co2c1000367/co2c1000367.rd.039.gz', 'co2c1000367/co2c1000367.rd.040.gz', 'co2c1000367/co2c1000367.rd.041.gz', 'co2c1000367/co2c1000367.rd.042.gz', 'co2c1000367/co2c1000367.rd.043.gz', 'co2c1000367/co2c1000367.rd.044.gz', 'co2c1000367/co2c1000367.rd.045.gz', 'co2c1000367/co2c1000367.rd.046.gz', 'co2c1000367/co2c1000367.rd.047.gz', 'co2c1000367/co2c1000367.rd.048.gz', 'co2c1000367/co2c1000367.rd.049.gz', 'co2c1000367/co2c1000367.rd.050.gz', 'co2c1000367/co2c1000367.rd.051.gz', 'co2c1000367/co2c1000367.rd.052.gz', 'co2c1000367/co2c1000367.rd.053.gz', 'co2c1000367/co2c1000367.rd.054.gz', 'co2c1000367/co2c1000367.rd.055.gz', 'co2c1000367/co2c1000367.rd.056.gz', 'co2c1000367/co2c1000367.rd.057.gz', 'co2c1000367/co2c1000367.rd.058.gz', 'co2c1000367/co2c1000367.rd.059.gz', 'co2c1000367/co2c1000367.rd.060.gz', 'co2c1000367/co2c1000367.rd.061.gz', 'co2c1000367/co2c1000367.rd.062.gz', 'co2c1000367/co2c1000367.rd.063.gz', 'co2c1000367/co2c1000367.rd.064.gz', 'co2c1000367/co2c1000367.rd.065.gz', 'co2c1000367/co2c1000367.rd.066.gz', 'co2c1000367/co2c1000367.rd.067.gz', 'co2c1000367/co2c1000367.rd.068.gz', 'co2c1000367/co2c1000367.rd.069.gz', 'co2c1000367/co2c1000367.rd.070.gz', 'co2c1000367/co2c1000367.rd.071.gz', 'co2c1000367/co2c1000367.rd.072.gz', 'co2c1000367/co2c1000367.rd.073.gz', 'co2c1000367/co2c1000367.rd.074.gz', 'co2c1000367/co2c1000367.rd.075.gz', 'co2c1000367/co2c1000367.rd.076.gz', 'co2c1000367/co2c1000367.rd.077.gz', 'co2c1000367/co2c1000367.rd.078.gz', 'co2c1000367/co2c1000367.rd.079.gz', 'co2c1000367/co2c1000367.rd.080.gz', 'co2c1000367/co2c1000367.rd.081.gz', 'co2c1000367/co2c1000367.rd.082.gz', 'co2c1000367/co2c1000367.rd.083.gz', 'co2c1000367/co2c1000367.rd.084.gz', 'co2c1000367/co2c1000367.rd.085.gz', 'co2c1000367/co2c1000367.rd.086.gz', 'co2c1000367/co2c1000367.rd.087.gz', 'co2c1000367/co2c1000367.rd.088.gz', 'co2c1000367/co2c1000367.rd.089.gz', 'co2c1000367/co2c1000367.rd.090.gz', 'co2c1000367/co2c1000367.rd.091.gz', 'co2c1000367/co2c1000367.rd.092.gz', 'co2c1000367/co2c1000367.rd.093.gz', 'co2c1000367/co2c1000367.rd.094.gz', 'co2c1000367/co2c1000367.rd.095.gz', 'co2c1000367/co2c1000367.rd.096.gz', 'co2c1000367/co2c1000367.rd.097.gz', 'co2c1000367/co2c1000367.rd.098.gz', 'co2c1000367/co2c1000367.rd.099.gz', 'co2c1000367/co2c1000367.rd.100.gz', 'co2c1000367/co2c1000367.rd.101.gz', 'co2c1000367/co2c1000367.rd.102.gz', 'co2c1000367/co2c1000367.rd.103.gz', 'co2c1000367/co2c1000367.rd.104.gz', 'co2c1000367/co2c1000367.rd.105.gz', 'co2c1000367/co2c1000367.rd.106.gz', 'co2c1000367/co2c1000367.rd.107.gz', 'co2c1000367/co2c1000367.rd.108.gz', 'co2c1000367/co2c1000367.rd.109.gz', 'co2c1000367/co2c1000367.rd.110.gz', 'co2c1000367/co2c1000367.rd.111.gz', 'co2c1000367/co2c1000367.rd.112.gz', 'co2c1000367/co2c1000367.rd.113.gz', 'co2c1000367/co2c1000367.rd.114.gz', 'co2c1000367/co2c1000367.rd.115.gz', 'co2c1000367/co2c1000367.rd.116.gz', 'co2c1000367/co2c1000367.rd.117.gz', 'co2c1000367/co2c1000367.rd.118.gz', 'co2c1000367/co2c1000367.rd.119.gz', 'co2c1000367/co2c1000367.rd.000.gz', 'co2c1000367/co2c1000367.rd.008.gz']\n"
          ]
        }
      ],
      "source": [
        "# Extract the files from the .tar.gz archive\n",
        "with tarfile.open(tar_file_path, 'r:gz') as tar:\n",
        "    # List all the files in the archive\n",
        "    file_list = tar.getnames()\n",
        "    print(file_list)\n",
        "    # Initialize a list to store DataFrames\n",
        "    dfs = []\n",
        "\n",
        "    # Loop through the files in the archive\n",
        "    for file_name in file_list:\n",
        "        if file_name.endswith('.gz'):\n",
        "            extracted_file = tar.extractfile(file_name)\n",
        "            decompressed_data = gzip.GzipFile(fileobj=extracted_file)\n",
        "            serial.append(file_name[-6:-3])\n",
        "            df = pd.read_csv(decompressed_data, delimiter='\\t')\n",
        "            dfs.append(df)\n",
        "\n",
        "# Now, data_frames contains DataFrames for all the .rd files in the archive\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IN5IiqDUqHyd"
      },
      "outputs": [],
      "source": [
        "j=0\n",
        "dcsv = []\n",
        "for df in dfs:\n",
        " # Access a specific cell by row and column index\n",
        "  if df.shape[0]>=16450:\n",
        "    value = df.iloc[2, 0]\n",
        "    mcond = \"\"\n",
        "    for i in value[2:]:\n",
        "      if(i==' '):\n",
        "        continue\n",
        "      if(i == ','):\n",
        "        break\n",
        "      # print(i)\n",
        "      mcond +=i\n",
        "      # print(mcond)\n",
        "\n",
        "    fcol=df.columns[0]\n",
        "    fn = fcol[10:13]\n",
        "    sid = fcol[5]\n",
        "    file_name = sid+\"_\"+fn+\"_\"+serial[j]+\"_\"+mcond\n",
        "    j+=1\n",
        "    #drop first three rows\n",
        "    df = df.drop(df.index[:3])\n",
        "    df = pd.DataFrame(df,columns=None)\n",
        "    #dataframe to csv and then csv to dataframe\n",
        "    df.to_csv(\"data.csv\")\n",
        "    df1 = pd.read_csv(\"data.csv\")\n",
        "    df1 = pd.DataFrame(df1,columns=None)\n",
        "\n",
        "    #split first column and make 4 columns\n",
        "    split_columns = df1[df.columns[0]].str.split(expand=True)\n",
        "    split_columns.columns = [\"trial number\", \"sensor position\", \"sample number (0-255)\", \"sensor value (in micro volts)\"]\n",
        "    df1 = pd.concat([df1, split_columns], axis=1)\n",
        "\n",
        "    # Drop the original 'Column1'\n",
        "    df1 = df1.drop(columns=[df.columns[0]])\n",
        "\n",
        "    #drop the unnamed:0\n",
        "    df1.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
        "    # print(df1.head(10))\n",
        "\n",
        "    df1 = df1[~df1.apply(lambda row: row.astype(str).str.contains('#').any(), axis=1)]\n",
        "\n",
        "    # Select the 4th column (index 3)\n",
        "    column_4_data = df1.iloc[:, 3].values\n",
        "\n",
        "    # Calculate the number of segments\n",
        "    segment_length = 256\n",
        "    num_segments = len(column_4_data) // segment_length\n",
        "\n",
        "    # Create a 2D array 'Sensor' with rows for each segment\n",
        "    Sensor = np.empty((num_segments, segment_length), dtype=column_4_data.dtype)\n",
        "\n",
        "    # Split the column data into segments and store them in 'Sensor'\n",
        "    for i in range(num_segments):\n",
        "      # print(i)\n",
        "      # Sensor[i]=sensor_pos[i]\n",
        "      start_index = i * segment_length\n",
        "      end_index = (i + 1) * segment_length\n",
        "      Sensor[i] = column_4_data[start_index:end_index]\n",
        "\n",
        "    # Now, 'Sensor' contains each segment of 255 values from the 4th column in separate rows\n",
        "\n",
        "    df2 = pd.DataFrame(Sensor)\n",
        "\n",
        "    #convert to csv download\n",
        "    file_name = f\"{file_name}.csv\"\n",
        "    file_path = output_directory + file_name\n",
        "    # df2.to_csv(file_path, index=False)\n",
        "    # dcsv.append(file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkTr7Pkjzw3d",
        "outputId": "8c1afe25-8ca6-4583-e7d4-70e90a4294b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "103\n"
          ]
        }
      ],
      "source": [
        "# Specify the directory path\n",
        "directory = \"/content/drive/MyDrive/Dataset/EEG_FULL/Non-alcoholic/367/\"\n",
        "df1=[]\n",
        "\n",
        "# Use glob to get a list of all .rd.*.gz files in the directory\n",
        "rd_gz_files = glob.glob(directory + '*.csv')\n",
        "# print(rd_gz_files)\n",
        "# Initialize an empty list to store DataFrames\n",
        "# Loop through the list of .rd.*.gz files and read them into DataFrames\n",
        "for file in rd_gz_files:\n",
        "  dff = pd.read_csv(file, delimiter=\"\\t\")\n",
        "  # serial.append(file[-6:-3])\n",
        "  df1.append(dff)\n",
        "# Now, the 'dfs' list contains all DataFrames from the .rd.*.gz files\n",
        "print(len(df1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vulzf-gLhK_r"
      },
      "outputs": [],
      "source": [
        "print(len(dfs))\n",
        "print(len(serial))\n",
        "# for srl in serial:\n",
        "#   print(srl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2-hBfWFWIQ3"
      },
      "outputs": [],
      "source": [
        "# Find list of files. how many files in a directory with specific words or alphabet\n",
        "# files = os.listdir(directory)\n",
        "\n",
        "# # Filter files containing '364' in their names\n",
        "# filtered_files = [file for file in files if '347' in file]\n",
        "# print(len(filtered_files))\n",
        "\n",
        "# # Sort the filtered files alphabetically\n",
        "# sorted_files = sorted(filtered_files)\n",
        "\n",
        "# # Print the filtered files\n",
        "# for file in filtered_files:\n",
        "#     print(file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dQJCElfOZno"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52aMwdPPTp_g"
      },
      "outputs": [],
      "source": [
        "# print(df2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdC5FsUmb8ke"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# import glob\n",
        "# import pandas as pd\n",
        "\n",
        "# # Set the directory where your data files are located\n",
        "# data_directory = '/content/drive/MyDrive/Dataset/smni_cmi_train/'\n",
        "\n",
        "# # Define the type of data you want to read (e.g., \"a\")\n",
        "# data_type = \"a\"\n",
        "\n",
        "# # Create a list of file paths for the selected data type\n",
        "# data_files = glob.glob(os.path.join(data_directory, f\"{data_type}_*.csv\"))\n",
        "# print(data_files)\n",
        "# # Initialize an empty list to store DataFrames\n",
        "# data_frames = []\n",
        "\n",
        "# # Loop through the files and read them into DataFrames\n",
        "# for file_path in data_files:\n",
        "#     df = pd.read_csv(file_path)\n",
        "#     data_frames.append(df)\n",
        "\n",
        "# # Now, data_frames contains DataFrames for the selected data type (\"a\")\n",
        "\n",
        "# # You can access individual DataFrames like data_frames[0], data_frames[1], etc.\n",
        "# print(len(data_frames))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1CHC2IDxIDDe1eQIpBPX7BqIhNwoupSO6",
      "authorship_tag": "ABX9TyP3IJcl9L2QoJ4EbFkyhXFc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}